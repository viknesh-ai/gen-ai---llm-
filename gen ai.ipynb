{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c02f32-3fa3-4d7e-99e0-774074742b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.1.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.5.1-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Downloading pillow-11.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./Python/venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./Python/venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in ./Python/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./Python/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./Python/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./Python/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in ./Python/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in ./Python/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in ./Python/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.20.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./Python/venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./Python/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./Python/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./Python/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./Python/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl (11.4 MB)\n",
      "Using cached numpy-2.1.3-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Downloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "Using cached torch-2.5.1-cp312-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading pillow-11.0.0-cp312-cp312-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl (11.0 MB)\n",
      "Using cached scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl (23.1 MB)\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl (381 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached tokenizers-0.20.3-cp312-cp312-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, tzdata, tqdm, threadpoolctl, sympy, safetensors, regex, Pillow, numpy, networkx, joblib, fsspec, filelock, torch, scipy, pandas, huggingface-hub, tokenizers, scikit-learn, transformers, sentence-transformers\n",
      "Successfully installed Pillow-11.0.0 filelock-3.16.1 fsspec-2024.10.0 huggingface-hub-0.26.3 joblib-1.4.2 mpmath-1.3.0 networkx-3.4.2 numpy-2.1.3 pandas-2.2.3 regex-2024.11.6 safetensors-0.4.5 scikit-learn-1.5.2 scipy-1.14.1 sentence-transformers-3.3.1 sympy-1.13.1 threadpoolctl-3.5.0 tokenizers-0.20.3 torch-2.5.1 tqdm-4.67.1 transformers-4.46.3 tzdata-2024.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers pandas numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05806d80-9607-4ef2-93e3-525216557e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "    id                                            subject  \\\n",
      "0   36  Anfrage zu den Spezifikationen und Anpassungso...   \n",
      "1   39               Déconnexions fréquentes et plantages   \n",
      "2  243                        Problema de sonido Dell XPS   \n",
      "3  381  Assistance requise pour la configuration du ta...   \n",
      "4  663  Urgente: Assistência Imediata Necessária para ...   \n",
      "\n",
      "                                                body  \\\n",
      "0  Sehr geehrtes Support-Team des Tech Online Sto...   \n",
      "1  Le client signale des déconnexions fréquentes ...   \n",
      "2  Problema con el sonido, manejando como devoluc...   \n",
      "3  Cher support client,\\n\\nNotre client, <name>, ...   \n",
      "4  Caro Suporte ao Cliente da Firma de Consultori...   \n",
      "\n",
      "                                              answer      type  \\\n",
      "0  Sehr geehrter <name>,\\n\\nvielen Dank für Ihr I...   Request   \n",
      "1  Nous allons enquêter sur le problème avec Zoom...  Incident   \n",
      "2  Gracias por su correo electrónico. Procesaremo...   Problem   \n",
      "3  Cher <name>,\\n\\nMerci de nous avoir contactés....   Request   \n",
      "4  Caro Cliente,\\n\\nRecebemos sua solicitação urg...  Incident   \n",
      "\n",
      "                   queue priority language                 business_type  \\\n",
      "0       Customer Service   medium       de             Tech Online Store   \n",
      "1        Product Support     high       fr  Software Development Company   \n",
      "2  Returns and Exchanges   medium       es             Tech Online Store   \n",
      "3        Product Support   medium       fr  Software Development Company   \n",
      "4        Human Resources   medium       pt            IT Consulting Firm   \n",
      "\n",
      "                   tag_1            tag_2               tag_3  \\\n",
      "0        Product Support    Sales Inquiry  Technical Guidance   \n",
      "1      Technical Support     Software Bug  Service Disruption   \n",
      "2  Returns and Exchanges  Product Support    Customer Service   \n",
      "3      Technical Support  Product Support     General Inquiry   \n",
      "4           Urgent Issue    Payroll Issue   Technical Support   \n",
      "\n",
      "                tag_4               tag_5               tag_6 tag_7 tag_8  \\\n",
      "0     General Inquiry                 NaN                 NaN   NaN   NaN   \n",
      "1        System Crash  Problem Resolution  Performance Tuning   NaN   NaN   \n",
      "2      Refund Request                 NaN                 NaN   NaN   NaN   \n",
      "3  Problem Resolution    Training Request                 NaN   NaN   NaN   \n",
      "4  Service Disruption  Problem Resolution  Account Assistance   NaN   NaN   \n",
      "\n",
      "   tag_9  \n",
      "0    NaN  \n",
      "1    NaN  \n",
      "2    NaN  \n",
      "3    NaN  \n",
      "4    NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = '/Users/vikneshv/Downloads/helpdesk_customer_tickets.csv'  # Replace with the path to your dataset\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f429a99f-c6e4-43a4-b728-292c78f548aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered relevant columns: 'subject', 'body', 'answer'.\n",
      "Total rows after filtering: 599\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_filtered = data[['subject', 'body', 'answer']].dropna()\n",
    "\n",
    "print(\"Filtered relevant columns: 'subject', 'body', 'answer'.\")\n",
    "print(f\"Total rows after filtering: {len(data_filtered)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81a40261-c122-41cc-a518-a3b64d63b9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikneshv/Python/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SentenceTransformer model...\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "print(\"Loading SentenceTransformer model...\")\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef4ac885-e896-446a-8f3b-89709f07f48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 'subject' and 'body' into a single text field.\n",
      "                                       combined_text\n",
      "0  Anfrage zu den Spezifikationen und Anpassungso...\n",
      "1  Déconnexions fréquentes et plantages Le client...\n",
      "2  Problema de sonido Dell XPS Problema con el so...\n",
      "3  Assistance requise pour la configuration du ta...\n",
      "4  Urgente: Assistência Imediata Necessária para ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_filtered['combined_text'] = data_filtered['subject'] + \" \" + data_filtered['body']\n",
    "\n",
    "print(\"Combined 'subject' and 'body' into a single text field.\")\n",
    "print(data_filtered[['combined_text']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eacde7a-c272-40e7-a486-7205ea9f4620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for the dataset... This may take some time.\n",
      "Embeddings generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "print(\"Generating embeddings for the dataset... This may take some time.\")\n",
    "embeddings = model.encode(data_filtered['combined_text'].tolist(), convert_to_tensor=True)\n",
    "\n",
    "print(\"Embeddings generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11fa32a2-f7d7-48f2-8ab7-4928fdaf4b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting embeddings to NumPy format...\n",
      "Embeddings stored in the dataset.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Converting embeddings to NumPy format...\")\n",
    "data_filtered['embedding'] = [emb.cpu().numpy() for emb in embeddings]\n",
    "\n",
    "print(\"Embeddings stored in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09bfedfe-e669-442d-b864-1968872ad4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to 'preprocessed_data.pkl'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_filtered.to_pickle('preprocessed_data.pkl')\n",
    "\n",
    "print(\"Preprocessed data saved to 'preprocessed_data.pkl'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e540341-99b2-47e2-b592-b4ab7f37b826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data...\n",
      "Preprocessed data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "print(\"Loading preprocessed data...\")\n",
    "data_filtered = pd.read_pickle('preprocessed_data.pkl')\n",
    "print(\"Preprocessed data loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06a49d6c-3661-42b1-8949-a24ed138c300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar entry found: \n",
      "Subject: Issue with Dell XPS 13 9310 After Update\n",
      "Body: Dear Tech Online Store customer support,\n",
      "\n",
      "I would like to report an issue regarding my Dell XPS 13 9310. After a recent Windows update, I have been experiencing screen flickering. This issue has made my laptop hard to use. Please advise on the next steps to resolve this.\n",
      "\n",
      "Thank you,\n",
      "<name>\n",
      "Answer: Dear <name>,\n",
      "\n",
      "Sorry to hear about the screen flickering on your Dell XPS 13 9310. We recommend updating your graphics drivers and checking for any additional Windows updates. If the issue persists, please contact our technical support for further assistance.\n",
      "\n",
      "Best regards,\n",
      "Tech Online Store Customer Support\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "\n",
    "data = pd.read_pickle('preprocessed_data.pkl')\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "query = \"Issue with Dell XPS 13 9310 After Update\"\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "precomputed_embeddings = torch.tensor(data['embedding'].values.tolist()).to(query_embedding.device)\n",
    "similarities = util.cos_sim(query_embedding, precomputed_embeddings).squeeze(0).cpu().numpy()\n",
    "most_similar_idx = similarities.argmax()\n",
    "best_match = data.iloc[most_similar_idx]\n",
    "print(f\"Most similar entry found: \\nSubject: {best_match['subject']}\\nBody: {best_match['body']}\\nAnswer: {best_match['answer']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6d4a5-85e3-40bf-bade-2d4f5bb1f5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a43c9f-922c-41b4-80ac-dfbc0074e9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
